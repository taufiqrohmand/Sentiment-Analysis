{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\maskers\\_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\maskers\\_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\maskers\\_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "c:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\explainers\\_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from Cleansing import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Kalimat Sentiment\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive\n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral\n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive\n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive\n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read data training\n",
    "train = pd.read_csv(\"dataset/train_preprocess.tsv.txt\", sep='\\t', names=['Kalimat','Sentiment'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cek data volume\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Kalimat      0\n",
       "Sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    6416\n",
       "negative    3436\n",
       "neutral     1148\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kalimat</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>warung dimiliki pengusaha pabrik puluhan terke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>mohon ulama lurus k212 mmbri hujjah partai diw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lokasi strategis jalan sumatra bandung nya nya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>positive</td>\n",
       "      <td>betapa bahagia nya unboxing paket barang nya b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>negative</td>\n",
       "      <td>aduh mahasiswa sombong kasih kartu kuning bela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Kalimat Sentiment  \\\n",
       "0  warung ini dimiliki oleh pengusaha pabrik tahu...  positive   \n",
       "1  mohon ulama lurus dan k212 mmbri hujjah partai...   neutral   \n",
       "2  lokasi strategis di jalan sumatera bandung . t...  positive   \n",
       "3  betapa bahagia nya diri ini saat unboxing pake...  positive   \n",
       "4  duh . jadi mahasiswa jangan sombong dong . kas...  negative   \n",
       "\n",
       "                                               Clean  \n",
       "0  warung dimiliki pengusaha pabrik puluhan terke...  \n",
       "1  mohon ulama lurus k212 mmbri hujjah partai diw...  \n",
       "2  lokasi strategis jalan sumatra bandung nya nya...  \n",
       "3  betapa bahagia nya unboxing paket barang nya b...  \n",
       "4  aduh mahasiswa sombong kasih kartu kuning bela...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Clean'] = train.Kalimat.apply(clean)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataprep = train.Clean.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction done\n",
      "  (0, 918)\t1\n",
      "  (0, 1013)\t1\n",
      "  (0, 1163)\t1\n",
      "  (0, 1488)\t1\n",
      "  (0, 1713)\t1\n",
      "  (0, 2098)\t1\n",
      "  (0, 3742)\t1\n",
      "  (0, 3794)\t2\n",
      "  (0, 4086)\t1\n",
      "  (0, 5365)\t1\n",
      "  (0, 5759)\t1\n",
      "  (0, 6297)\t1\n",
      "  (0, 6474)\t1\n",
      "  (0, 7329)\t1\n",
      "  (0, 8398)\t1\n",
      "  (0, 8470)\t1\n",
      "  (0, 9197)\t2\n",
      "  (0, 9228)\t1\n",
      "  (0, 10067)\t1\n",
      "  (0, 10306)\t1\n",
      "  (0, 10998)\t1\n",
      "  (0, 11786)\t1\n",
      "  (0, 11824)\t1\n",
      "  (0, 12861)\t1\n",
      "  (0, 14113)\t1\n",
      "  :\t:\n",
      "  (10999, 911)\t1\n",
      "  (10999, 1168)\t1\n",
      "  (10999, 1224)\t1\n",
      "  (10999, 1383)\t1\n",
      "  (10999, 1485)\t1\n",
      "  (10999, 1867)\t1\n",
      "  (10999, 1999)\t1\n",
      "  (10999, 4020)\t1\n",
      "  (10999, 4763)\t1\n",
      "  (10999, 4764)\t1\n",
      "  (10999, 6212)\t1\n",
      "  (10999, 6312)\t1\n",
      "  (10999, 7406)\t1\n",
      "  (10999, 7735)\t1\n",
      "  (10999, 7873)\t1\n",
      "  (10999, 8026)\t1\n",
      "  (10999, 8027)\t2\n",
      "  (10999, 10067)\t3\n",
      "  (10999, 11410)\t1\n",
      "  (10999, 11411)\t1\n",
      "  (10999, 12207)\t1\n",
      "  (10999, 12243)\t1\n",
      "  (10999, 14653)\t1\n",
      "  (10999, 14809)\t1\n",
      "  (10999, 15531)\t1\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(dataprep)\n",
    "\n",
    "X = cv.transform(dataprep)\n",
    "print('Feature Extraction done')\n",
    "print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv, open('asset/feature.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        positive\n",
       "1         neutral\n",
       "2        positive\n",
       "3        positive\n",
       "4        negative\n",
       "           ...   \n",
       "10995    positive\n",
       "10996    positive\n",
       "10997     neutral\n",
       "10998    negative\n",
       "10999    positive\n",
       "Name: Sentiment, Length: 11000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = train.Sentiment\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training selesai\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print('Training selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('asset/model.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing selesai\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78       704\n",
      "     neutral       0.76      0.69      0.72       217\n",
      "    positive       0.88      0.91      0.90      1279\n",
      "\n",
      "    accuracy                           0.84      2200\n",
      "   macro avg       0.81      0.79      0.80      2200\n",
      "weighted avg       0.84      0.84      0.84      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = model.predict(X_test)\n",
    "\n",
    "print ('testing selesai')\n",
    "print(classification_report(Y_test, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionError",
     "evalue": "The passed data does not match the background shape expected by the masker! The data of shape (1, 15611) was passed while the masker expected data of shape (15611,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDimensionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mExplainer(model\u001b[39m.\u001b[39mpredict_proba, X_train)\n\u001b[1;32m----> 2\u001b[0m shap_values \u001b[39m=\u001b[39m explainer(X_train[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      3\u001b[0m shap\u001b[39m.\u001b[39mplots\u001b[39m.\u001b[39mtext(shap_values)\n",
      "File \u001b[1;32mc:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\explainers\\_permutation.py:82\u001b[0m, in \u001b[0;36mPermutation.__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, max_evals\u001b[39m=\u001b[39m\u001b[39m500\u001b[39m, main_effects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, error_bounds\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     79\u001b[0m              outputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, silent\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m     80\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Explain the output of the model on the given arguments.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\n\u001b[0;32m     83\u001b[0m         \u001b[39m*\u001b[39;49margs, max_evals\u001b[39m=\u001b[39;49mmax_evals, main_effects\u001b[39m=\u001b[39;49mmain_effects, error_bounds\u001b[39m=\u001b[39;49merror_bounds, batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     84\u001b[0m         outputs\u001b[39m=\u001b[39;49moutputs, silent\u001b[39m=\u001b[39;49msilent\n\u001b[0;32m     85\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\explainers\\_explainer.py:266\u001b[0m, in \u001b[0;36mExplainer.__call__\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *args, **kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m     feature_names \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(args))]\n\u001b[0;32m    265\u001b[0m \u001b[39mfor\u001b[39;00m row_args \u001b[39min\u001b[39;00m show_progress(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39margs), num_rows, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m explainer\u001b[39m\u001b[39m\"\u001b[39m, silent):\n\u001b[1;32m--> 266\u001b[0m     row_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexplain_row(\n\u001b[0;32m    267\u001b[0m         \u001b[39m*\u001b[39mrow_args, max_evals\u001b[39m=\u001b[39mmax_evals, main_effects\u001b[39m=\u001b[39mmain_effects, error_bounds\u001b[39m=\u001b[39merror_bounds,\n\u001b[0;32m    268\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size, outputs\u001b[39m=\u001b[39moutputs, silent\u001b[39m=\u001b[39msilent, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    269\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     values\u001b[39m.\u001b[39mappend(row_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    271\u001b[0m     output_indices\u001b[39m.\u001b[39mappend(row_result\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39moutput_indices\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\explainers\\_permutation.py:92\u001b[0m, in \u001b[0;36mPermutation.explain_row\u001b[1;34m(self, max_evals, main_effects, error_bounds, batch_size, outputs, silent, *row_args)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Explains a single row and returns the tuple (row_values, row_expected_values, row_mask_shapes).\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# build a masked version of the model for the current input sample\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m fm \u001b[39m=\u001b[39m MaskedModel(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasker, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlink, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlinearize_link, \u001b[39m*\u001b[39;49mrow_args)\n\u001b[0;32m     94\u001b[0m \u001b[39m# by default we run 10 permutations forward and backward\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m max_evals \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\utils\\_masked_model.py:28\u001b[0m, in \u001b[0;36mMaskedModel.__init__\u001b[1;34m(self, model, masker, link, linearize_link, *args)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m# if the masker supports it, save what positions vary from the background\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmasker, \u001b[39m\"\u001b[39m\u001b[39minvariants\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants \u001b[39m=\u001b[39m \u001b[39m~\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasker\u001b[39m.\u001b[39;49minvariants(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants_column_sums \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants\u001b[39m.\u001b[39msum(\u001b[39m0\u001b[39m)\n\u001b[0;32m     30\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants_row_inds \u001b[39m=\u001b[39m [\n\u001b[0;32m     31\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants[:,i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variants\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m     32\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\BAV USER\\Python\\lib\\site-packages\\shap\\maskers\\_tabular.py:145\u001b[0m, in \u001b[0;36mTabular.invariants\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[39m# make sure we got valid data\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m--> 145\u001b[0m     \u001b[39mraise\u001b[39;00m DimensionError(\n\u001b[0;32m    146\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe passed data does not match the background shape expected by the masker! The data of shape \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \\\n\u001b[0;32m    147\u001b[0m         \u001b[39mstr\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m was passed while the masker expected data of shape \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39misclose(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "\u001b[1;31mDimensionError\u001b[0m: The passed data does not match the background shape expected by the masker! The data of shape (1, 15611) was passed while the masker expected data of shape (15611,)."
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(model.predict_proba, X_train)\n",
    "shap_values = explainer(X_train[0])\n",
    "shap.plots.text(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KFold object with 5 splits and a fixed random state\n",
    "Kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "akurasi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ke:  1\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.73      0.74       680\n",
      "     neutral       0.80      0.67      0.73       239\n",
      "    positive       0.86      0.90      0.88      1281\n",
      "\n",
      "    accuracy                           0.82      2200\n",
      "   macro avg       0.80      0.76      0.78      2200\n",
      "weighted avg       0.82      0.82      0.82      2200\n",
      "\n",
      "Training ke:  2\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.75      0.76       706\n",
      "     neutral       0.78      0.67      0.72       220\n",
      "    positive       0.87      0.91      0.89      1274\n",
      "\n",
      "    accuracy                           0.83      2200\n",
      "   macro avg       0.81      0.78      0.79      2200\n",
      "weighted avg       0.83      0.83      0.83      2200\n",
      "\n",
      "Training ke:  3\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.74      0.76       682\n",
      "     neutral       0.81      0.73      0.76       215\n",
      "    positive       0.87      0.91      0.89      1303\n",
      "\n",
      "    accuracy                           0.84      2200\n",
      "   macro avg       0.82      0.79      0.81      2200\n",
      "weighted avg       0.84      0.84      0.84      2200\n",
      "\n",
      "Training ke:  4\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.75      0.76       698\n",
      "     neutral       0.82      0.68      0.74       229\n",
      "    positive       0.87      0.90      0.89      1273\n",
      "\n",
      "    accuracy                           0.83      2200\n",
      "   macro avg       0.82      0.78      0.80      2200\n",
      "weighted avg       0.83      0.83      0.83      2200\n",
      "\n",
      "Training ke:  5\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.80      0.78       670\n",
      "     neutral       0.79      0.65      0.71       245\n",
      "    positive       0.90      0.91      0.91      1285\n",
      "\n",
      "    accuracy                           0.85      2200\n",
      "   macro avg       0.82      0.79      0.80      2200\n",
      "weighted avg       0.85      0.85      0.85      2200\n",
      "\n",
      "rata-rata akurasi:  0.8481818181818181\n"
     ]
    }
   ],
   "source": [
    "for iteration, data in enumerate(Kf.split(X), start=1):\n",
    "    data_train = X[data[0]]\n",
    "    target_train = Y[data[0]]\n",
    "\n",
    "    data_test = X[data[1]]\n",
    "    target_test = Y[data[1]]\n",
    "\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(data_train, target_train)\n",
    "    \n",
    "    pred = clf.predict(data_test)\n",
    "    accuracy = accuracy_score(target_test,pred)\n",
    "\n",
    "    print(\"Training ke: \", iteration)\n",
    "    print(\"---\")\n",
    "    print(classification_report(target_test,pred))\n",
    "\n",
    "akurasi.append(accuracy)\n",
    "print(\"rata-rata akurasi: \", np.mean(akurasi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bacot!!!! kamu terlalu banyak bicara\n",
      "sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "ori = '''\n",
    "bacot!!!! kamu terlalu banyak bicara'''\n",
    "\n",
    "te = cv.transform([clean(ori)])\n",
    "res = model.predict(te)[0]\n",
    "\n",
    "print(ori)\n",
    "print('sentiment:', res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
